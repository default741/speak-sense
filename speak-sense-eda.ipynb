{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpeakSense - Language Detection System\n",
    "\n",
    "The objective of this project is to develop a robust and accurate system capable of detecting the language spoken in audio recordings. By leveraging advanced machine learning algorithms and signal processing techniques, the system aims to accurately identify the language spoken in various audio inputs, spanning diverse accents, dialects, and environmental conditions. This language detection solution seeks to provide practical applications in speech recognition, transcription, translation, and other fields requiring language-specific processing, thereby enhancing accessibility and usability across linguistic boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import opendatasets as od\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "import librosa\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "if not (os.path.exists('./data/audio-dataset-with-10-indian-languages') or os.path.exists('./data/audio_dataset_indian_languages')):\n",
    "    od.download(dataset_id_or_url=\"https://www.kaggle.com/datasets/hbchaitanyabharadwaj/audio-dataset-with-10-indian-languages\", data_dir='./data/')\n",
    "    os.rename('./data/audio-dataset-with-10-indian-languages/', './data/audio_dataset_indian_languages/')\n",
    "\n",
    "if not (os.path.exists('./data/spoken-language-identification') or os.path.exists('./data/spoken_language_identification')):\n",
    "    od.download(dataset_id_or_url=\"https://www.kaggle.com/datasets/toponowicz/spoken-language-identification\", data_dir='./data/')\n",
    "    os.rename('./data/spoken-language-identification/', './data/spoken_language_identification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoken_languages_train_path_dataset = './data/spoken_language_identification/train/train/'\n",
    "indian_languages_train_path_dataset = './data/audio_dataset_indian_languages/Language Detection Dataset/*/*.mp3'\n",
    "\n",
    "filename_de = ['de_f_0809fd0642232f8c85b0b3d545dc2b5a.fragment1.flac', 'de_f_5d2e7f30d69f2d1d86fd05f3bbe120c2.fragment1.flac']\n",
    "filename_en = ['en_f_058b70233667e1b64506dddf9f9d6b46.fragment1.flac', 'en_f_386ee651f6f1539ff5622c55e234e5a4.fragment3.flac']\n",
    "filename_es = ['es_f_47bd2e6178465cd745c86c9db5ffe447.fragment1.flac', 'es_f_ea5fee5b16a663c988fbddb2137cf573.fragment15.flac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_de, sample_rate_de = librosa.load(spoken_languages_train_path_dataset + filename_de[0])\n",
    "print(f'Audio Data Sample Rate: {sample_rate_de}')\n",
    "\n",
    "ipd.Audio(data=data_de, rate=sample_rate_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en, sample_rate_en = librosa.load(spoken_languages_train_path_dataset + filename_en[0])\n",
    "print(f'Audio Data Sample Rate: {sample_rate_en}')\n",
    "\n",
    "ipd.Audio(data=data_en, rate=sample_rate_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_es, sample_rate_es = librosa.load(spoken_languages_train_path_dataset + filename_es[0])\n",
    "print(f'Audio Data Sample Rate: {sample_rate_es}')\n",
    "\n",
    "ipd.Audio(data=data_es, rate=sample_rate_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bengali, sample_rate_bengali = librosa.load('./data/audio_dataset_indian_languages/Language Detection Dataset/Bengali/0.mp3')\n",
    "print(f'Audio Data Sample Rate: {sample_rate_bengali}')\n",
    "\n",
    "ipd.Audio(data=data_bengali, rate=sample_rate_bengali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gujarati, sample_rate_gujarati = librosa.load('./data/audio_dataset_indian_languages/Language Detection Dataset/Gujarati/214.mp3')\n",
    "print(f'Audio Data Sample Rate: {sample_rate_gujarati}')\n",
    "\n",
    "ipd.Audio(data=data_gujarati, rate=sample_rate_gujarati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hindi, sample_rate_hindi = librosa.load('./data/audio_dataset_indian_languages/Language Detection Dataset/Hindi/0.mp3')\n",
    "print(f'Audio Data Sample Rate: {sample_rate_hindi}')\n",
    "\n",
    "ipd.Audio(data=data_hindi, rate=sample_rate_hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kannada, sample_rate_kannada = librosa.load('./data/audio_dataset_indian_languages/Language Detection Dataset/Kannada/214.mp3')\n",
    "print(f'Audio Data Sample Rate: {sample_rate_kannada}')\n",
    "\n",
    "ipd.Audio(data=data_kannada, rate=sample_rate_kannada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_malayalam, sample_rate_malayalam = librosa.load('./data/audio_dataset_indian_languages/Language Detection Dataset/Malayalam/214.mp3')\n",
    "print(f'Audio Data Sample Rate: {sample_rate_malayalam}')\n",
    "\n",
    "ipd.Audio(data=data_malayalam, rate=sample_rate_malayalam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_marathi, sample_rate_marathi = librosa.load('./data/audio_dataset_indian_languages/Language Detection Dataset/Marathi/214.mp3')\n",
    "print(f'Audio Data Sample Rate: {sample_rate_marathi}')\n",
    "\n",
    "ipd.Audio(data=data_marathi, rate=sample_rate_marathi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_punjabi, sample_rate_punjabi = librosa.load('./data/audio_dataset_indian_languages/Language Detection Dataset/Punjabi/214.mp3')\n",
    "print(f'Audio Data Sample Rate: {sample_rate_punjabi}')\n",
    "\n",
    "ipd.Audio(data=data_punjabi, rate=sample_rate_punjabi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tamil, sample_rate_tamil = librosa.load('./data/audio_dataset_indian_languages/Language Detection Dataset/Tamil/214.mp3')\n",
    "print(f'Audio Data Sample Rate: {sample_rate_tamil}')\n",
    "\n",
    "ipd.Audio(data=data_tamil, rate=sample_rate_tamil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_telugu, sample_rate_telugu = librosa.load('./data/audio_dataset_indian_languages/Language Detection Dataset/Telugu/214.mp3')\n",
    "print(f'Audio Data Sample Rate: {sample_rate_telugu}')\n",
    "\n",
    "ipd.Audio(data=data_telugu, rate=sample_rate_telugu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_urdu, sample_rate_urdu = librosa.load('./data/audio_dataset_indian_languages/Language Detection Dataset/Urdu/214.mp3')\n",
    "print(f'Audio Data Sample Rate: {sample_rate_urdu}')\n",
    "\n",
    "ipd.Audio(data=data_urdu, rate=sample_rate_urdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitude_plot_audio(data_dict: dict, n_rows: int = 1, n_cols: int = 3, figsize: tuple = (20, 5), file_name: str = 'amplitude_plot'):\n",
    "    _, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=figsize)\n",
    "\n",
    "    for key in data_dict.keys():\n",
    "        idx, lang = key.split('_')\n",
    "        idx = int(idx)\n",
    "\n",
    "        ax[idx].plot(data_dict[key])\n",
    "\n",
    "        ax[idx].set_ylabel('Amplitude')\n",
    "        ax[idx].set_xlabel('Time in samples')\n",
    "        ax[idx].set_title(f'Audio Amplitude vs Time ({lang})')\n",
    "\n",
    "    plt.savefig(f'./data/eda_results/{file_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(filename_de)):\n",
    "    data_de, _ = librosa.load(spoken_languages_train_path_dataset + filename_de[i])\n",
    "    data_en, _ = librosa.load(spoken_languages_train_path_dataset + filename_en[i])\n",
    "    data_es, _ = librosa.load(spoken_languages_train_path_dataset + filename_es[i])\n",
    "\n",
    "    data_dict = {'0_de': data_de, '1_en': data_en, '2_es': data_es}\n",
    "\n",
    "    amplitude_plot_audio(data_dict=data_dict, file_name='amplitude_plot_de_en_es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_languages_list = ['Hindi', 'Bengali', 'Gujarati']\n",
    "data_dict = {}\n",
    "\n",
    "for idx, lang in enumerate(indian_languages_list):\n",
    "    data_dict[f'{idx}_{lang.lower()}'] = librosa.load(f'./data/audio_dataset_indian_languages/Language Detection Dataset/{lang}/214.mp3')[0]\n",
    "\n",
    "amplitude_plot_audio(data_dict=data_dict, file_name='amplitude_plot_hbg')\n",
    "\n",
    "indian_languages_list = ['Kannada', 'Malayalam', 'Marathi']\n",
    "data_dict = {}\n",
    "\n",
    "for idx, lang in enumerate(indian_languages_list):\n",
    "    data_dict[f'{idx}_{lang.lower()}'] = librosa.load(f'./data/audio_dataset_indian_languages/Language Detection Dataset/{lang}/214.mp3')[0]\n",
    "\n",
    "amplitude_plot_audio(data_dict=data_dict, file_name='amplitude_plot_kmm')\n",
    "\n",
    "indian_languages_list = ['Punjabi', 'Tamil', 'Telugu', 'Urdu']\n",
    "data_dict = {}\n",
    "\n",
    "for idx, lang in enumerate(indian_languages_list):\n",
    "    data_dict[f'{idx}_{lang.lower()}'] = librosa.load(f'./data/audio_dataset_indian_languages/Language Detection Dataset/{lang}/214.mp3')[0]\n",
    "\n",
    "amplitude_plot_audio(data_dict=data_dict, n_rows=1, n_cols=4, figsize=(25, 5), file_name='amplitude_plot_pttu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectogram_plot_audio(data_dict: dict, sample_rate_dict: dict, n_rows: int = 1, n_cols: int = 3, figsize: tuple = (20, 5), file_name: str = 'amplitude_plot'):\n",
    "    _, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=figsize)\n",
    "\n",
    "    for key in data_dict.keys():\n",
    "        idx, lang = key.split('_')\n",
    "        idx = int(idx)\n",
    "\n",
    "        ax[idx].specgram(data_dict[key], Fs=sample_rate_dict[key])\n",
    "\n",
    "        ax[idx].set_ylabel('Frequency [Hz]')\n",
    "        ax[idx].set_xlabel('Time [sec]')\n",
    "        ax[idx].set_title(f'Audio Frequency vs Time ({lang})')\n",
    "\n",
    "    plt.savefig(f'./data/eda_results/{file_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(filename_de)):\n",
    "    data_de, samplerate_de = librosa.load(spoken_languages_train_path_dataset + filename_de[i])\n",
    "    data_en, samplerate_en = librosa.load(spoken_languages_train_path_dataset + filename_en[i])\n",
    "    data_es, samplerate_es = librosa.load(spoken_languages_train_path_dataset + filename_es[i])\n",
    "\n",
    "    data_dict = {'0_de': data_de, '1_en': data_en, '2_es': data_es}\n",
    "    sample_rate_dict = {'0_de': samplerate_de, '1_en': samplerate_en, '2_es': samplerate_es}\n",
    "\n",
    "    spectogram_plot_audio(data_dict=data_dict, sample_rate_dict=sample_rate_dict, file_name='spectogram_plot_de_en_es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_languages_list = ['Hindi', 'Bengali', 'Gujarati']\n",
    "data_dict = {}\n",
    "sample_rate_dict = {}\n",
    "\n",
    "for idx, lang in enumerate(indian_languages_list):\n",
    "    data, sample_rate = librosa.load(f'./data/audio_dataset_indian_languages/Language Detection Dataset/{lang}/214.mp3')\n",
    "\n",
    "    data_dict[f'{idx}_{lang.lower()}'] = data\n",
    "    sample_rate_dict[f'{idx}_{lang.lower()}'] = sample_rate\n",
    "\n",
    "spectogram_plot_audio(data_dict=data_dict, sample_rate_dict=sample_rate_dict, file_name='spectogram_plot_hbg')\n",
    "\n",
    "indian_languages_list = ['Kannada', 'Malayalam', 'Marathi']\n",
    "audio_file_name = '214'\n",
    "data_dict = {}\n",
    "sample_rate_dict = {}\n",
    "\n",
    "for idx, lang in enumerate(indian_languages_list):\n",
    "    data, sample_rate = librosa.load(f'./data/audio_dataset_indian_languages/Language Detection Dataset/{lang}/{audio_file_name}.mp3')\n",
    "\n",
    "    data_dict[f'{idx}_{lang.lower()}'] = data\n",
    "    sample_rate_dict[f'{idx}_{lang.lower()}'] = sample_rate\n",
    "\n",
    "spectogram_plot_audio(data_dict=data_dict, sample_rate_dict=sample_rate_dict, file_name='spectogram_plot_kmm')\n",
    "\n",
    "indian_languages_list = ['Punjabi', 'Tamil', 'Telugu', 'Urdu']\n",
    "audio_file_name = '214'\n",
    "data_dict = {}\n",
    "sample_rate_dict = {}\n",
    "\n",
    "for idx, lang in enumerate(indian_languages_list):\n",
    "    data, sample_rate = librosa.load(f'./data/audio_dataset_indian_languages/Language Detection Dataset/{lang}/{audio_file_name}.mp3')\n",
    "\n",
    "    data_dict[f'{idx}_{lang.lower()}'] = data\n",
    "    sample_rate_dict[f'{idx}_{lang.lower()}'] = sample_rate\n",
    "\n",
    "spectogram_plot_audio(data_dict=data_dict, sample_rate_dict=sample_rate_dict, n_rows=1, n_cols=4, figsize=(25, 5), file_name='spectogram_plot_pttu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name: str) -> tuple:\n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, sr=None)\n",
    "        audio_duration_sec = int(librosa.get_duration(y=audio_data, sr=sample_rate))\n",
    "\n",
    "        return (sample_rate, audio_duration_sec)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {str(e)}\")\n",
    "\n",
    "        return (np.nan, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoken_language_dataframe = pd.DataFrame({'file_name': [spoken_languages_train_path_dataset + file_name for file_name in os.listdir(spoken_languages_train_path_dataset)]})\n",
    "spoken_language_dataframe['language_label'] = spoken_language_dataframe['file_name'].str.split('/', expand=True).iloc[:, 5].str.split('_', expand=True).iloc[:, 0].replace(to_replace={\n",
    "    'de': 'german', 'en': 'english', 'es': 'spanish'})\n",
    "\n",
    "indian_language_dataframe = pd.DataFrame({'file_name': glob.glob(indian_languages_train_path_dataset)})\n",
    "indian_language_dataframe['language_label'] = indian_language_dataframe['file_name'].str.split('\\\\', expand=True).iloc[:, 1].str.lower()\n",
    "\n",
    "indian_language_dataframe = indian_language_dataframe[indian_language_dataframe['language_label'] != 'punjabi']\n",
    "\n",
    "language_dataframe = pd.concat([spoken_language_dataframe, indian_language_dataframe], ignore_index=True)\n",
    "language_dataframe['file_size_kb'] = (language_dataframe['file_name'].apply(lambda x: os.path.getsize(x)) / 1024).round(3)\n",
    "\n",
    "language_dataframe.to_csv('./data/model_data/language_dataframe_v1.csv', index=False)\n",
    "\n",
    "for lang in tqdm(language_dataframe['language_label'].unique(), desc=\"Languages\"):\n",
    "    lang_data = language_dataframe[language_dataframe['language_label'] == lang].copy()\n",
    "    lang_data[['sample_rate', 'audio_duration_sec']] = lang_data['file_name'].apply(lambda file_name: pd.Series(load_data(file_name=file_name)))\n",
    "\n",
    "    lang_data.to_csv(f'./data/model_data/data_subset/language_dataframe_{lang}_v1.csv', index=False)\n",
    "\n",
    "language_dataframe = pd.concat([pd.read_csv(f'./data/model_data/data_subset/language_dataframe_{lang}_v1.csv') for lang in language_dataframe['language_label'].unique()], ignore_index=True).dropna()\n",
    "language_dataframe.to_csv('./data/model_data/language_dataframe_v1.csv', index=False)\n",
    "\n",
    "language_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_dataframe = pd.read_csv('./data/model_data/language_dataframe_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_dataframe['sample_rate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_dataframe['file_size_kb'].mean(), language_dataframe['file_size_kb'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_dataframe['audio_duration_sec'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academics-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
